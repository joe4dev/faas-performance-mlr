@article{ESENCE2017628,
title = "A review on experience feedback and numerical modeling of packed-bed thermal energy storage systems",
journal = "Solar Energy",
volume = "153",
pages = "628 - 654",
year = "2017",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2017.03.032",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X17301925",
author = "Thibaut Esence and Arnaud Bruch and Sophie Molina and Benoit Stutz and Jean-François Fourmigué",
keywords = "Thermal energy storage, Packed bed, Thermocline, Concentrated solar power (CSP)",
abstract = "Solar thermal energy is a clean, climate-friendly and inexhaustible energy resource. It is therefore promising to cope with fossil fuel depletion and climate change. Thermal storage enables to make this intermittent energy resource dispatchable, reliable on demand and more competitive. Nowadays, most of the concentrated solar power plants equipped with integrated thermal storage systems use the two-tank molten salt technology. Despite its relative simplicity and efficiency, this technology is expensive and requires huge amounts of nitrate salts. In the short to medium term, packed-bed thermal energy storage with either liquid or gaseous heat transfer fluid is a promising alternative to reduce storage costs and hence improve the development of solar energy. To design reliable, efficient and cost-effective packed-bed storage systems, this technology, which involves many physical phenomena, has to be better understood. This paper aims to sum up some key aspects about design, operation, and performances of packed-bed storage systems. In the first part, most representative setups and their experience feedback are presented. The controllability of packed-bed storage systems and the special influence of thermal stratification are pointed out. In the second part, the various numerical models used to predict packed-bed storage performances are reviewed. In the last part, some useful correlations enabling to quantify the main physical phenomena involved in packed-bed operation and modeling are presented and compared. The correlations investigated enable to calculate fluid/solid and fluid/wall heat transfer coefficients, effective thermal conductivity and pressure drop in packed beds."
}
@article{CHANG201676,
title = "Passenger facility charge vs. airport improvement program funds: A dynamic network DEA analysis for U.S. airport financing",
journal = "Transportation Research Part E: Logistics and Transportation Review",
volume = "88",
pages = "76 - 93",
year = "2016",
issn = "1366-5545",
doi = "https://doi.org/10.1016/j.tre.2016.02.001",
url = "http://www.sciencedirect.com/science/article/pii/S1366554515301678",
author = "Young-Tae Chang and Hyosoo (Kevin) Park and Bo Zou and Nabin Kafle",
keywords = "Passenger Facility Charge (PFC), Airport Improvement Program (AIP), Substitution, Dynamic network DEA, Airport efficiency",
abstract = "Passenger Facility Charge (PFC) and the Airport Improvement Program (AIP) are two major sources to finance U.S. airports. This paper develops a novel dynamic network DEA framework to investigate the substitutability between PFC and AIP funds. We find that the studied U.S. airports can substitute PFC for 8–35% of the current AIP funds and contribute significantly to the proposed plan of the US congress to cut AIP funding. In addition, the amount of PFC-for-AIP funds substitution negatively correlates with the productive efficiency of airports. The findings send an important message for future policy reforms on U.S. airport financing."
}
@article{WANG20182,
title = "Electron-driven heterogeneous catalytic synthesis of ammonia: Current states and perspective",
journal = "Carbon Resources Conversion",
volume = "1",
number = "1",
pages = "2 - 31",
year = "2018",
issn = "2588-9133",
doi = "https://doi.org/10.1016/j.crcon.2018.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S258891331830022X",
author = "Ke Wang and Daniel Smith and Ying Zheng",
abstract = "Ammonia is the second most produced chemical worldwide that makes up 80% of nitrogen-based fertilisers, which have supported approximately 27% of the world’s population over the last century. The Haber–Bosch process, which is the main process for producing ammonia, is extremely energy intensive and consumes around 1% of the world’s energy. Additionally, it requires hydrogen gas as a reactant that is produced via steam reforming which emits carbon dioxide as a by-product. Over 500 million tonnes of ammonia are produced per year via industrial processes which required 3–5% of total natural gas consumption worldwide and also accounted for 2% global energy usage. Therefore, more sustainable processes, such as electrocatalysis and photocatalysis, using electrons and the transfer of protons has been investigated. This review covers the most state-of-the-art technologies used to produce ammonia via electrocatalysis and photocatalysis by comparing different electrolyte systems and electrocatalysts as well as discussing issues with these methods and possible solutions. In addition, substantial improvements to electrocatalysts and photocatalysts as well as methods to prevent both the promotion of the hydrogen evolution reaction and the decomposition of ammonia at higher temperatures are reviewed. Challenges and perspectives are discussed."
}
@article{OSSA2019351,
title = "Performance of a pavement foundation system based on the partial compensation of masses method",
journal = "Soils and Foundations",
volume = "59",
number = "2",
pages = "351 - 366",
year = "2019",
issn = "0038-0806",
doi = "https://doi.org/10.1016/j.sandf.2018.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S0038080619300149",
author = "A. Ossa and E. Botero and M.C. Madrigal and E. Ovando and M. Mendoza and N.P. López-Acosta",
keywords = "Partial compensation of masses, Texcoco Lake soils, Runway foundation system, Soft soils",
abstract = "The system of the partial compensation of masses in the lacustrine zone of the Mexico Basin has been conceptualized, developed, used and improved over the past five decades as a foundation alternative for different types of roadways. This kind of foundation has been used in highways and runways built on lacustrine soils to reduce the settlement that can affect the service and operation conditions of those structures. In the construction of the new Mexico City International Airport in the Texcoco Lake area, various alternatives for runway foundations were evaluated through different test sections that were constructed to identify which of them would yield an adequate transfer of stress and prevent excessive total and differential deformations of the soil deposits. In this work, the behavior of the test section of the system of the partial compensation of masses, built in the Texcoco Lake area, is studied. An exploration campaign was performed; it consisted of different field and laboratory tests to determine the stratigraphic profile and the index and mechanical properties of the soil strata. Numerical models were applied using the finite element software PLAXIS 2D to analyze the behavior of the test section and to determine the maintenance frequency required to preserve the functionality of future runways. To validate the capability of the numerical models to properly simulate the stress-strain behavior of the test section, a comparative analysis was performed between the data obtained from the instrumentation installed on the test section and the results obtained from the finite element software. Once the numerical models were calibrated, the medium- and long-term behaviors of the test section were predicted, and the evolution over time of its surface geometry and transverse slopes were obtained."
}
@incollection{20191001,
editor = "Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach",
booktitle = "Encyclopedia of Bioinformatics and Computational Biology",
publisher = "Academic Press",
address = "Oxford",
pages = "1001 - 1077",
year = "2019",
isbn = "978-0-12-811432-2",
doi = "https://doi.org/10.1016/B978-0-12-809633-8.09001-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128096338090014"
}
@incollection{WANG2017239,
title = "Chapter 9 - Single Event Effects in Avionics",
editor = "Peng Wang",
booktitle = "Civil Aircraft Electrical Power System Safety Assessment",
publisher = "Butterworth-Heinemann",
pages = "239 - 258",
year = "2017",
isbn = "978-0-08-100721-1",
doi = "https://doi.org/10.1016/B978-0-08-100721-1.00009-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780081007211000091",
author = "Peng Wang",
keywords = "Single Event Effects, SRAM, irradiation experiment, flight experiment",
abstract = "With the improvement of integrated circuit technology, chips contain more and more functions. For airborne electronic hardware, the radiation effect poses more and more hidden dangers to the safety of aircraft. According to the current technological trends, in the next decade, if civil aircraft continues to use a large number of highly integrated electronic components and microprocessors, taking additional protective measures, then the average probability of catastrophic failure conditions caused by radiation-induced failure of aircraft hardware and software in the next decade will increase by at least 10 times. This will be a major risk to aviation safety. Therefore, the Single Event Effects problem needs to be taken into account at the Preliminary System Safety Assessment process at the beginning of the system design."
}
@article{GRIBAUDO20181032,
title = "A performance modeling framework for lambda architecture based applications",
journal = "Future Generation Computer Systems",
volume = "86",
pages = "1032 - 1041",
year = "2018",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.07.033",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17315364",
author = "M. Gribaudo and M. Iacono and M. Kiran",
keywords = "Modeling languages, Lambda architectural pattern, Performance evaluation, Multiformalism modeling, Multisolution methods, Cloud, Analytical approach",
abstract = "The lambda architectural pattern allows to overcome some limitations of data processing frameworks. It builds on the methodology of having two different data processing streams on the same system: a real time computing for fast data streams and a batch computing behavior for massive workloads for delayed processing. While these two modes are clearly not new, lambda architectures allow them to coordinate their execution to avoid interference. However resource allocation over cloud infrastructure, has greatly impacted the overall performances (and importantly costs). If performance could be modeled in advance, architects could make better judgments on allocation of their resources to use the systems more efficiently. In this paper, we present a modeling approach, based on multiformalism and multisolution techniques, that provides a fast evaluation tool to support design choices about parameters and eventually lead to better architecture designs."
}
@article{DIFRANCESCO201977,
title = "Architecting with microservices: A systematic mapping study",
journal = "Journal of Systems and Software",
volume = "150",
pages = "77 - 97",
year = "2019",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2019.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S0164121219300019",
author = "Paolo Di Francesco and Patricia Lago and Ivano Malavolta",
keywords = "Microservices, Software architecture, Systematic mapping study",
abstract = "Context
A microservice architecture is composed of a set of small services, each running in its own process and communicating with lightweight mechanisms. Many aspects on architecting with microservices are still unexplored and existing research is still far from being crispy clear.
Objective
We aim at identifying, classifying, and evaluating the state of the art on architecting with microservices from the following perspectives: publication trends, focus of research, and potential for industrial adoption.
Method
We apply the systematic mapping methodology. We rigorously selected 103 primary studies and we defined and applied a classification framework to them for extracting key information for subsequent analysis. We synthesized the obtained data and produced a clear overview of the state of the art.
Results
This work contributes with (i) a classification framework for research studies on architecting with microservices, (ii) a systematic map of current research of the field, (iii) an evaluation of the potential for industrial adoption of research results, and (iv) a discussion of emerging findings and implications for future research.
Conclusion
This study provides a solid, rigorous, and replicable picture of the state of the art on architecting with microservices. Its results can benefit both researchers and practitioners of the field."
}
@article{ALFEO201819,
title = "Design and simulation of the emergent behavior of small drones swarming for distributed target localization",
journal = "Journal of Computational Science",
volume = "29",
pages = "19 - 33",
year = "2018",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2018.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S1877750318302898",
author = "Antonio L. Alfeo and Mario G.C.A. Cimino and Nicoletta De Francesco and Massimiliano Lega and Gigliola Vaglini",
keywords = "Swarm intelligence, Drone, Stigmergy, Flocking, Differential evolution, Target search",
abstract = "A swarm of autonomous drones with self-coordination and environment adaptation can offer a robust, scalable and flexible manner to localize objects in an unexplored, dangerous or unstructured environment. We design a novel coordination algorithm combining three biologically inspired processes: stigmergy, flocking and evolution. Stigmergy, a form of coordination exhibited by social insects, is exploited to attract drones in areas with potential targets. Flocking enables efficient cooperation between flock mates upon target detection, while keeping an effective scan. The two mechanisms can interoperate if their structural parameters are correctly tuned for a given scenario. Differential evolution adapts the swarm coordination according to environmental conditions. The performance of the proposed algorithm is examined with synthetic and real-world scenarios."
}
@article{JACQUILLAT2018168,
title = "A roadmap toward airport demand and capacity management",
journal = "Transportation Research Part A: Policy and Practice",
volume = "114",
pages = "168 - 185",
year = "2018",
issn = "0965-8564",
doi = "https://doi.org/10.1016/j.tra.2017.09.027",
url = "http://www.sciencedirect.com/science/article/pii/S096585641630355X",
author = "Alexandre Jacquillat and Amedeo R. Odoni",
keywords = "Airport management, Capacity planning, Airport operations, Demand management",
abstract = "This paper synthesizes the major interventions available to manage airport demand and capacity, the analytical tools that may support the underlying policy, managerial and operational decisions, and guidelines for policy and practice obtained from recent research. The resulting insights fall into three broad categories. First, airport throughput exhibits significant variability, and airport capacity depends on the available infrastructure and operating procedures. Second, airport on-time performance is highly non-linear, and thus sensitive to variations in demand and capacity. Third, airport demand management involves a trade-off between mitigating congestion and maximizing capacity utilization, and scheduling mechanisms can support and enhance existing practices. The implications for the development and management of airport systems worldwide are discussed."
}
@incollection{PAIDOUSSIS20161,
title = "Chapter 1 - Cylindrical Shells Containing or Immersed in Flow: Advanced Topics and Applications",
editor = "Michael P. Païdoussis",
booktitle = "Fluid-Structure Interactions (Second Edition)",
publisher = "Academic Press",
edition = "Second Edition",
address = "Oxford",
pages = "1 - 141",
year = "2016",
isbn = "978-0-12-397333-7",
doi = "https://doi.org/10.1016/B978-0-12-397333-7.00001-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780123973337000012",
author = "Michael P. Païdoussis",
keywords = "Coaxial cylindrical shells, Internal and annular flow, Swirling flow, Static divergence, Flutter, Turbulence-induced vibration, Physiological systems, Collapsible tubes, Flow limitation, Flow-induced oscillations",
abstract = "The dynamics of coaxial cylindrical shells with internal or annular, inviscid or viscous flow is discussed. Both analytical and CFD models and experiments are presented. Static and dynamic instabilities arise for shells with supported ends or cantilevered ones at high enough flowrates. The boundary-layer pressure fluctuations in the flow are also considered, and turbulence-induced vibration determined by a hybrid finite-element model and the joint acceptance approach. The dynamics of collapsible tubes (pliable shells) is discussed next for physiological systems mainly: blood flow in veins and air-flow in the lungs. After a thorough literature review, some of the basic analytical models for flow-induced oscillations are presented, ending with the latest sloshing model. Engineering applications are presented last."
}
@article{GRANGE201656,
title = "Numerical investigation of the heat transfer in an aeronautical composite material under fire stress",
journal = "Fire Safety Journal",
volume = "80",
pages = "56 - 63",
year = "2016",
issn = "0379-7112",
doi = "https://doi.org/10.1016/j.firesaf.2016.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0379711216300066",
author = "N. Grange and K. Chetehouna and N. Gascoin and S. Senave",
keywords = "Fireproof tests, Aircraft certification, Thermal degradation, Carbon–phenolic composite, Benchmark of turbulence models",
abstract = "The use of composite materials for aeronautical applications has been growing since several years because of the opportunity to produce lightweight structures reducing the fuel bills and emissions. The need for fireproof certification imposes costly and time consuming experiments that might be replaced or complemented in the years to come by numerical calculations. The present work creates a CFD numerical model of a fireproof test. As an example, a composite part located in an aircraft APU (auxiliary power unit) which provides electric power to the aircraft is investigated. A numerical calibration of the flame is conducted according to the fireproof standards. After that, a comparison between three different turbulence models shows that the k–ε realisable turbulence model is the more suitable for fireproof numerical tests with discrepancies lower than 16% between computed values and measured ones. The influence of an internal air jet is observed for velocities from 1 to 10m/s. The results demonstrate a good evaluation on how this could reduce the wall temperatures and ensure the requirements of the certification rules compare to the actual external thermal protection used to ensure the certification requirements. Indeed, final temperature reductions up to 45% are found at reference point on the structure with the highest value of air jet velocity."
}
@article{MARINKAS2018242,
title = "Anion-conductive membranes based on 2-mesityl-benzimidazolium functionalised poly(2,6-dimethyl-1,4-phenylene oxide) and their use in alkaline water electrolysis",
journal = "Polymer",
volume = "145",
pages = "242 - 251",
year = "2018",
issn = "0032-3861",
doi = "https://doi.org/10.1016/j.polymer.2018.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S0032386118303951",
author = "Angela Marinkas and Izabela Struźyńska-Piron and Yona Lee and Ahyoun Lim and Hyun S. Park and Jong Hyun Jang and Hyoung-Juhn Kim and Jihyun Kim and Artjom Maljusch and Oliver Conradi and Dirk Henkensmeier",
keywords = "Anion exchange membrane, 2-Mesityl-benzimidazole, Poly(2,6-dimethyl-1,4-phenylene oxide) (PPO), Alkaline electrolysis, Alkaline stability",
abstract = "For development of anion exchange membrane (AEM) water electrolysis systems, a series of polymers was synthesised by reacting 2-mesityl-benzimidazole (BIM) and brominated poly-(2,6-dimethyl-1,4-phenylene oxide) (Br-PPO) in a Menshutkin reaction, and permethylating the attached BIM groups. The degree of bromination of Br-PPO can be easily monitored by IR spectroscopy: A correlation with the shift of the band around 1190 cm−1 was found. The IEC values of the prepared materials ranged between 1.6 and 2.9 mmol OH− g−1. Only materials with an IEC value of 1.9 (PPO24-BIM) reproducibly formed self-supporting membranes. This may be related to the degree of crystallinity, which decreased from 14 to 3% when the IEC increased from 1.6 to 3 mmol OH− g−1. Materials with IEC values of 1.6 and 2.2 can form self-supporting membranes, but not reproducibly. PPO24-BIM showed a conductivity of 8 mS cm-1 at room temperature, a thermal stability well above 200 °C, and mechanical properties similar to those of commercial FAA3-30 membranes. During water electrolysis, a current density of 300 mA cm-2 at 1.8 V was obtained. At 80 °C in 1 M KOH, degradation of BIM and the PPO backbone were observed by IR spectroscopy and monitoring conductivity and weight loss."
}
@article{KILKIS20171068,
title = "Benchmarking aircraft metabolism based on a Sustainable Airline Index",
journal = "Journal of Cleaner Production",
volume = "167",
pages = "1068 - 1083",
year = "2017",
issn = "0959-6526",
doi = "https://doi.org/10.1016/j.jclepro.2017.03.183",
url = "http://www.sciencedirect.com/science/article/pii/S0959652617306443",
author = "Şan Kılkış and Şiir Kılkış",
keywords = "Airlines, Aviation, Aircraft metabolism, Composite index, Sustainability, CO emissions",
abstract = "Airlines are mobile, micro-communities that exhibit varying levels of performance. This paper develops and applies a composite indicator to address a gap in the literature for benchmarking airlines based on aspects of sustainable aviation. First, the concept of aircraft metabolism is developed to relate flows of energy, carbon dioxide emissions, water, and waste with operational outputs, such as the transport of revenue loads. The Sustainable Airline Index is then constructed based on 4 dimensions and 20 indicators to benchmark aircraft metabolism. The dimensions are 1) airline services and quality, 2) fuel consumption and efficiency, 3) carbon dioxide emissions and intensity, and 4) sustainable aviation measures. The index is applied to a sample of 16 airlines based on data from corporate sustainability reporting and annual reports. The results are compared based on six schemes that involve equal or unequal weights with linear or geometric aggregation. Unequal weights are determined based on exploratory factor analysis. The net change in rank among all schemes is 2.3 positions. Monte Carlo experiments are also conducted to rank airlines based on simulated mean values in which the top 4 airlines in the sample are A9, A11, A3 and A15. Airlines that decouple revenue loads from similar increases in resource usage have higher rankings in the composite indicator based on well-rounded performances in aircraft metabolism. The results are applicable to support the carbon neutral growth strategy of the sector and to consider multiple dimensions towards more sustainable practices on the airside of aviation."
}
@article{ZOU201566,
title = "US airport financial reform and its implications for airport efficiency: An exploratory investigation",
journal = "Journal of Air Transport Management",
volume = "47",
pages = "66 - 78",
year = "2015",
issn = "0969-6997",
doi = "https://doi.org/10.1016/j.jairtraman.2015.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0969699715000575",
author = "Bo Zou and Nabin Kafle and Young-Tae Chang and Kevin Park",
keywords = "Airport productive efficiency, Airport finance, Airport Improvement Program (AIP), Passenger Facility Charge (PFC), Data Envelopment Analysis (DEA), Undesirable output",
abstract = "This study investigates the effect on airport productive efficiency of two major funding sources used by US airports, namely the Airport Improvement Program (AIP) grants and the Passenger Facility Charges (PFC). A two-stage Data Envelopment Analysis (DEA) modeling approach is employed for this purpose. In the first stage, we estimate airport productive efficiency using a variable returns-to-scale DEA model with both desirable and undesirable outputs. In the second stage, random effects regression models are estimated with airport efficiency scores from the first stage as the dependent variable and PFC and a proxy for AIP grants as two of the explanatory variables. By applying the two-stage DEA model to 42 primary US airports, it is found that PFC use has a positive impact on airport productive efficiency, whereas the impact of AIP grants is negative. Multiple counterfactual scenarios are examined by altering the mix of the two types of funding sources. The results show that simultaneously raising the PFC ceiling and decreasing AIP grants could lead to greater airport productive efficiency. The US federal aviation authority would also benefit from realizing these scenarios, especially given the budgetary constraints it faces."
}
@article{ENES2018420,
title = "BDWatchdog: Real-time monitoring and profiling of Big Data applications and frameworks",
journal = "Future Generation Computer Systems",
volume = "87",
pages = "420 - 437",
year = "2018",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.12.068",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17316096",
author = "Jonatan Enes and Roberto R. Expósito and Juan Touriño",
keywords = "Big data, Monitoring, Profiling, Time series, Flame graphs, Process-based analysis",
abstract = "Current Big Data applications are characterized by a heavy use of system resources (e.g., CPU, disk) generally distributed across a cluster. To effectively improve their performance there is a critical need for an accurate analysis of both Big Data workloads and frameworks. This means to fully understand how the system resources are being used in order to identify potential bottlenecks, from resource to code bottlenecks. This paper presents BDWatchdog, a novel framework that allows real-time and scalable analysis of Big Data applications by combining time series for resource monitorization and flame graphs for code profiling, focusing on the processes that make up the workload rather than the underlying instances on which they are executed. This shift from the traditional system-based monitorization to a process-based analysis is interesting for new paradigms such as software containers or serverless computing, where the focus is put on applications and not on instances. BDWatchdog has been evaluated on a Big Data cloud-based service deployed at the CESGA supercomputing center. The experimental results show that a process-based analysis allows for a more effective visualization and overall improves the understanding of Big Data workloads. BDWatchdog is publicly available at http://bdwatchdog.dec.udc.es."
}
@article{FIROOZ2019410,
title = "A new selective optode for the determination of iron(III) based on the immobilization of morin on triacetylcellulose: A combined experimental and computational study",
journal = "Materials Science and Engineering: C",
volume = "94",
pages = "410 - 416",
year = "2019",
issn = "0928-4931",
doi = "https://doi.org/10.1016/j.msec.2018.09.031",
url = "http://www.sciencedirect.com/science/article/pii/S0928493117338535",
author = "A.R. Firooz and M. Movahedi and H. Sabzyan",
keywords = "Fe(III) ion, Morin, Optode, Triacetylcellulose, Iron(III) optical sensor, Serum iron, DFT",
abstract = "Accurate and fast measurement of the iron ion in biological, pharmaceutical and medical samples is of great applied importance. In this work, a novel optical sensor (optode) for the Fe(III) ion is fabricated based on the immobilization of morin (2′,3,4′,5,7-pentahydroxyflavone) on a triacetylcellulose membrane. Chemical binding of the Fe(III) ion with the immobilized morin is monitored spectrophotometrically at 334 nm. The prepared optode shows excellent response over a wide range of concentrations from 1.06 × 10−10 to 4.73 × 10−5 M with a detection limit of 4.23 × 10−11 M Fe(III). Effects of the factors determining sensitivity of the optode are studied and optimized. The prepared optical sensor shows good selectivity toward the Fe(III) ion in the presence of a number of other metal ions. The developed sensor is applied successfully and satisfactorily for the determination of iron in three pharmaceutical, one plasma and two serum samples. In addition, concentration of the Fe(III) ion in two tap water samples is measured using standard addition method. Density functional theory (TD) B3LYP/6-311++G** method is used to investigate structure and binding characteristics, and calculate the UV–Vis spectrum of the Fe(III)-morin complex."
}
@article{ALVAREZMIRANDA201763,
title = "A Relax-and-Cut framework for large-scale maximum weight connected subgraph problems",
journal = "Computers & Operations Research",
volume = "87",
pages = "63 - 82",
year = "2017",
issn = "0305-0548",
doi = "https://doi.org/10.1016/j.cor.2017.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0305054817301272",
author = "Eduardo Álvarez-Miranda and Markus Sinnl",
keywords = "Maximum weight connected subgraph problem, Lagrangian pelaxation, Bioinformatics",
abstract = "Finding maximum weight connected subgraphs within networks is a fundamental combinatorial optimization problem both from theoretical and practical standpoints. One of the most prominent applications of this problem appears in Systems Biology and it corresponds to the detection of active subnetworks within gene interaction networks. Due to its importance, several modeling and algorithmic strategies have been proposed for tackling the maximum weight connected subgraph problem (MWCS) over the last years; the most effective strategies typically depend on the use of integer linear programming (ILP). Nonetheless, this implies that large-scale networks (such as those appearing in Systems Biology) can become burdensome; moreover, not all practitioners may have access to an ILP solver. In this paper, a unified modeling and algorithmic scheme is designed to solve the MWCS and some of its application-oriented variants with cardinality-constraints or budget-constraints. The proposed framework is based on a general node-based model which is tackled by a Relax-and-Cut scheme, i.e., Lagrangian relaxation combined with constraint generation; this yields a heuristic procedure capable of providing both dual and primal bounds. The approach is enhanced by additional valid inequalities, lifted valid inequalities, primal heuristics and variable-fixing procedures. Computational results on instances from the literature, as well as on additional large-scale instances, show that the proposed framework is competitive with respect to the existing approaches and it allows to find improved solutions for some unsolved instances from literature. The effect of initializing a Branch-and-Cut approach with information from the Relax-and-Cut is also investigated. The implemented approach is made available online."
}
@article{ARIYALURANHABEEB2019289,
title = "Real-time big data processing for anomaly detection: A Survey",
journal = "International Journal of Information Management",
volume = "45",
pages = "289 - 307",
year = "2019",
issn = "0268-4012",
doi = "https://doi.org/10.1016/j.ijinfomgt.2018.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0268401218301658",
author = "Riyaz Ahamed Ariyaluran Habeeb and Fariza Nasaruddin and Abdullah Gani and Ibrahim Abaker Targio Hashem and Ejaz Ahmed and Muhammad Imran",
keywords = "Real-time, Big data processing, Anomaly detection and machine learning algorithms",
abstract = "The advent of connected devices and omnipresence of Internet have paved way for intruders to attack networks, which leads to cyber-attack, financial loss, information theft in healthcare, and cyber war. Hence, network security analytics has become an important area of concern and has gained intensive attention among researchers, off late, specifically in the domain of anomaly detection in network, which is considered crucial for network security. However, preliminary investigations have revealed that the existing approaches to detect anomalies in network are not effective enough, particularly to detect them in real time. The reason for the inefficacy of current approaches is mainly due the amassment of massive volumes of data though the connected devices. Therefore, it is crucial to propose a framework that effectively handles real time big data processing and detect anomalies in networks. In this regard, this paper attempts to address the issue of detecting anomalies in real time. Respectively, this paper has surveyed the state-of-the-art real-time big data processing technologies related to anomaly detection and the vital characteristics of associated machine learning algorithms. This paper begins with the explanation of essential contexts and taxonomy of real-time big data processing, anomalous detection, and machine learning algorithms, followed by the review of big data processing technologies. Finally, the identified research challenges of real-time big data processing in anomaly detection are discussed."
}
@article{ARNALDOVALDES2018216,
title = "Prediction of aircraft safety incidents using Bayesian inference and hierarchical structures",
journal = "Safety Science",
volume = "104",
pages = "216 - 230",
year = "2018",
issn = "0925-7535",
doi = "https://doi.org/10.1016/j.ssci.2018.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S0925753517301868",
author = "Rosa María Arnaldo Valdés and V. Fernando Gómez Comendador and Luis Perez Sanz and Alvaro Rodriguez Sanz",
keywords = "Risk, Incident rate, Predictive models, Bayesian inference, Hierarchical models",
abstract = "Today, aviation is immersed in a shift from old-fashioned reactive and compliance-based safety approaches towards proactive and performance-based methods and tools. Stakeholders have to monitor, gather and analyse safety-related data and information in order to anticipate and predict actual and emerging safety risks. In this context safety analytics and statistics need to evolve to forecast future safety performances and risks. This research adopts an innovative statistical approach involving the use of Bayesian inference and Hierarchical structures to develop statistical estimation and prediction models with different complexities and objectives. The study develops and analyses five Bayesian models of increasing difficulty, two basic and three Hierarchical models, which allows us to explore safety incident data, efficiently identify anomalies, assess the level of risk, define an objective framework for comparing air carriers, and finally predict and anticipate incidents."
}
@article{ALJERI2019101930,
title = "A two-tier machine learning-based handover management scheme for intelligent vehicular networks",
journal = "Ad Hoc Networks",
volume = "94",
pages = "101930",
year = "2019",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2019.101930",
url = "http://www.sciencedirect.com/science/article/pii/S157087051930160X",
author = "Noura Aljeri and Azzedine Boukerche",
abstract = "With the increasing demand for real-time road safety services and infotainment applications on vehicles, the development of an efficient wireless mobile communication became crucial for the content delivery of such services in Intelligent Vehicular Networks (IVN). Mobility management enables mobile hosts to communicate over the Internet from foreign networks. However, vehicles' high mobility and the rapid shifts in network topology affect the performance of traditional mobility management protocols. Hence, raising the challenge for seamless wireless communications over IVN. In this paper, we propose a two-tier Machine Learning-based scheme for handover management in intelligent vehicular networks. In the first tier, we use a recurrent neural network model to predict the receiving signal strength of Access Points (APs), to derive a handover trigger decision. In the second tier, a stochastic Markov model is used to select the next access point by utilizing the vehicle flow projections. The performance of the proposed protocol is evaluated using NS-2 simulator and generated vehicles mobility. Simulation results show that the proposed ML-based model outperformed related work in term of prediction accuracy, while the integration of the handover trigger scheme and the access point selection method improved network performance."
}
@article{2019S1,
title = "Abstracts of the 55th Congress of the European Societies of Toxicology (EUROTOX 2019) TOXICOLOGY SCIENCE PROVIDING SOLUTIONS",
journal = "Toxicology Letters",
volume = "314",
pages = "S1 - S309",
year = "2019",
note = "Abstracts of the 55th Congress of the European Societies of Toxicology (EUROTOX 2019) TOXICOLOGY – SCIENCE PROVIDING SOLUTIONS",
issn = "0378-4274",
doi = "https://doi.org/10.1016/j.toxlet.2019.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0378427419302486"
}
@article{LEITNER2019340,
title = "A mixed-method empirical study of Function-as-a-Service software development in industrial practice",
journal = "Journal of Systems and Software",
volume = "149",
pages = "340 - 359",
year = "2019",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2018.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S0164121218302735",
author = "Philipp Leitner and Erik Wittern and Josef Spillner and Waldemar Hummer",
keywords = "Cloud computing, Serverless, Function-as-a-Service, Empirical research",
abstract = "Function-as-a-Service (FaaS) describes cloud computing services that make infrastructure components transparent to application developers, thus falling in the larger group of “serverless” computing models. When using FaaS offerings, such as AWS Lambda, developers provide atomic and short-running code for their functions, and FaaS providers execute and horizontally scale them on-demand. Currently, there is no systematic research on how developers use serverless, what types of applications lend themselves to this model, or what architectural styles and practices FaaS-based applications are based on. We present results from a mixed-method study, combining interviews with practitioners who develop applications and systems that use FaaS, a systematic analysis of grey literature, and a Web-based survey. We find that successfully adopting FaaS requires a different mental model, where systems are primarily constructed by composing pre-existing services, with FaaS often acting as the “glue” that brings these services together. Tooling availability and maturity, especially related to testing and deployment, remains a major difficulty. Further, we find that current FaaS systems lack systematic support for function reuse, and abstractions and programming models for building non-trivial FaaS applications are limited. We conclude with a discussion of implications for FaaS providers, software developers, and researchers."
}
@article{ZHOU201552,
title = "The performance of corporate financial distress prediction models with features selection guided by domain knowledge and data mining approaches",
journal = "Knowledge-Based Systems",
volume = "85",
pages = "52 - 61",
year = "2015",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2015.04.017",
url = "http://www.sciencedirect.com/science/article/pii/S0950705115001616",
author = "Ligang Zhou and Dong Lu and Hamido Fujita",
keywords = "Financial distress prediction, Features selection, Domain knowledge, Data mining",
abstract = "Experts in finance and accounting select feature subset for corporate financial distress prediction according to their professional understanding of the characteristics of the features, while researchers in data mining often believe that data alone can tell everything and they use various mining techniques to search the feature subset without considering the financial and accounting meanings of the features. This paper investigates the performance of different financial distress prediction models with features selection approaches based on domain knowledge or data mining techniques. The empirical results show that there is no significant difference between the best classification performance of models with features selection guided by data mining techniques and that by domain knowledge. However, the combination of domain knowledge and genetic algorithm based features selection method can outperform unique domain knowledge and unique data mining based features selection method on AUC performance."
}
@article{GIMENEZALVENTOSA2019259,
title = "A framework and a performance assessment for serverless MapReduce on AWS Lambda",
journal = "Future Generation Computer Systems",
volume = "97",
pages = "259 - 274",
year = "2019",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2019.02.057",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X18325172",
author = "V. Giménez-Alventosa and Germán Moltó and Miguel Caballer",
keywords = "MapReduce, Serverless, Cloud computing, Elasticity",
abstract = "MapReduce is one of the most widely used programming models for analysing large-scale datasets, i.e. Big Data. In recent years, serverless computing and, in particular, Functions as a Service (FaaS) has surged as an execution model in which no explicit management of servers (e.g. virtual machines) is performed by the user. Instead, the Cloud provider dynamically allocates resources to the function invocations and fine-grained billing is introduced depending on the execution time and allocated memory, as exemplified by AWS Lambda. In this article, a high-performant serverless architecture has been created to execute MapReduce jobs on AWS Lambda using Amazon S3 as the storage backend. In addition, a thorough assessment has been carried out to study the suitability of AWS Lambda as a platform for the execution of High Throughput Computing jobs. The results indicate that AWS Lambda provides a convenient computing platform for general-purpose applications that fit within the constraints of the service (15 min of maximum execution time, 3008 MB of RAM and 512 MB of disk space) but it exhibits an inhomogeneous performance behaviour that may jeopardise adoption for tightly coupled computing jobs."
}
@incollection{WANG2019169,
title = "Chapter 3 - Shock tube techniques for kinetic target data to improve reaction models",
editor = "Tiziano Faravelli and Flavio Manenti and Eliseo Ranzi",
series = "Computer Aided Chemical Engineering",
publisher = "Elsevier",
volume = "45",
pages = "169 - 202",
year = "2019",
booktitle = "Mathematical Modelling of Gas-Phase Complex Reaction Systems: Pyrolysis and Combustion",
issn = "1570-7946",
doi = "https://doi.org/10.1016/B978-0-444-64087-1.00003-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780444640871000036",
author = "Shengkai Wang and David F. Davidson and Ronald K. Hanson",
keywords = "Shock tube, Reaction kinetics, Combustion diagnostics, Laser absorption",
abstract = "Modern shock tube techniques are extremely useful in providing critical kinetic targets for the development, evaluation, and optimization of mathematical models of gas-phase complex reaction systems. This chapter provides an overview of the fundamental principles and key data types of shock tube kinetic measurements for improving reaction models, along with recent advancements in shock tube methodologies and precision diagnostics that extended reaction kinetics measurement capability to an exciting new level."
}
@incollection{CLOTE2015287,
title = "Chapter Twelve - Computational Prediction of Riboswitches",
editor = "Shi-Jie Chen and Donald H. Burke-Aguero",
series = "Methods in Enzymology",
publisher = "Academic Press",
volume = "553",
pages = "287 - 312",
year = "2015",
booktitle = "Computational Methods for Understanding Riboswitches",
issn = "0076-6879",
doi = "https://doi.org/10.1016/bs.mie.2014.10.063",
url = "http://www.sciencedirect.com/science/article/pii/S0076687914000640",
author = "P. Clote",
keywords = "Riboswitch, Conformational switch, Machine learning, Thermodynamics-based algorithm, Noncoding RNA",
abstract = "Riboswitches present a ubiquitous genetic regulatory mechanism for prokaryotes and have been found in HIV1, fungi, plants, and even H. sapiens. We present an overview of approaches to predict riboswitch aptamers and, more generally, RNA conformational switches."
}
@article{ROMERO201925,
title = "Improving conversion of d-Glucose into short-chain alkanes over Ru/MCM-48 based catalysts",
journal = "Microporous and Mesoporous Materials",
volume = "286",
pages = "25 - 35",
year = "2019",
issn = "1387-1811",
doi = "https://doi.org/10.1016/j.micromeso.2019.05.035",
url = "http://www.sciencedirect.com/science/article/pii/S1387181119303415",
author = "Alberto Romero and Antonio Nieto-Márquez and Nadine Essayem and Esther Alonso and Catherine Pinel",
keywords = "Alkanes, Ruthenium, Al-MCM-48, Biomass, Tungstophosphoric acid",
abstract = "The production of fuels from biomass is a key factor for sustainability. With this aim, we have studied the conversion of d-Glucose into short-chain alkanes in a one-pot biphasic catalytic system, evaluating different modifications of Ru/MCM-48: Ru/Al-MCM-48 and Ru/MCM-48 with the addition of tungstophosphoric acid, and compared with a commercial Ru/C. Additionally, different combinations of the previous were studied. Catalysts were characterized in terms of X-ray Diffraction/Small Angle X-Ray Scattering, N2 adsorption/desorption, Temperature Programmed Reduction with H2, Temperature Programmed Desorption of Ammonia, Transmission Electron Microscopy and Atomic Absorption. The reaction was carried out at 190 °C under 5 MPa of H2 in a biphasic n-decane–water system. In the absence of tungstophosphoric acid, the reaction took place through a first hydrogenation to sorbitol followed by dehydration and hydrodeoxigenation. In this terms, the presence of Al-MCM-48 showed to play a very important role in the production of light alkanes, favoring the dehydration step. The reverse trend was observed in the presence of tungstophosphoric acid. In this case, the reaction occurred first by the dehydration of glucose, followed by hydrogenation and hydrodeoxigenation. Here, once the dehydration had been promoted by tungstophosphoric acid, the following hydrogenation step was favored on Ru/C, which is preferentially located in the organic phase. The global results, in terms of alkane formation, shows how the presence of Al-MCM-48 conducts to promising results, outperforming commercial or other literature reported systems."
}
@article{SIDIROPOULOS2018160,
title = "A framework for the optimization of terminal airspace operations in Multi-Airport Systems",
journal = "Transportation Research Part B: Methodological",
volume = "110",
pages = "160 - 187",
year = "2018",
issn = "0191-2615",
doi = "https://doi.org/10.1016/j.trb.2018.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S0191261517302072",
author = "Stavros Sidiropoulos and Arnab Majumdar and Ke Han",
keywords = "Multi-Airport System, Metroplex, Spatio-temporal clustering, Analytic hierarchy process, 3-D route design",
abstract = "Major cities like London, New York, and Tokyo are served by several airports, effectively creating a Multi-Airport System (MAS), or Metroplex. The operations of individual Metroplex airports are highly interdependent, rendering their efficient management rather difficult. This paper proposes a framework for the design of dynamic arrival and departure routes in MAS Terminal Maneuvering Areas, which fundamentally changes the operation in MAS airspaces for much improved efficiency when compared to the current situation. The framework consists of three components. The first presents a new procedure for characterizing dynamic arrival and departure routes based on the spatio-temporal distributions of flights. The second component is a novel Analytic Hierarchy Process (AHP) model for the prioritization of the dynamic routes, which takes into account a set of quantitative and qualitative attributes important for MAS operations. The third component is a priority-based method for the positioning of terminal waypoints as well as the design of three-dimensional, conflict-free terminal routes. Such a method accounts for the AHP-derived priorities while satisfying the minimal separation and aircraft maneuverability constraints. The developed framework is applied to a case study of the New York Metroplex, using aircraft trajectories during a heavy traffic period on typical day of operation in the New York Terminal Control Area in November 2011. The proposed framework is quantitatively assessed using the AirTOp fast-time simulation model. The results suggest significant improvements of the new design over the existing one, as measured by several key performance indicators such as travel distance, travel time, fuel burn, and controller workload. The operational feasibility of the framework is further validated qualitatively by subject matter experts from the Port Authority of New York and New Jersey, the operator of the New York Metroplex."
}
@article{MEDEL2018286,
title = "Characterising resource management performance in Kubernetes",
journal = "Computers & Electrical Engineering",
volume = "68",
pages = "286 - 297",
year = "2018",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2018.03.041",
url = "http://www.sciencedirect.com/science/article/pii/S0045790617315240",
author = "Víctor Medel and Rafael Tolosana-Calasanz and José Ángel Bañares and Unai Arronategui and Omer F. Rana",
keywords = "Performance models, Container lifecycle, Cloud resource management, Petri nets, Kubernetes",
abstract = "A key challenge for supporting elastic behaviour in cloud systems is to achieve a good performance in automated (de-)provisioning and scheduling of computing resources. One of the key aspects that can be significant is the overheads associated with deploying, terminating and maintaining resources. Therefore, due to their lower start up and termination overhead, containers are rapidly replacing Virtual Machines (VMs) in many cloud deployments, as the computation instance of choice. In this paper, we analyse the performance of Kubernetes achieved through a Petri net-based performance model. Kubernetes is a container management system for a distributed cluster environment. Our model can be characterised using data from a Kubernetes deployment, and can be exploited for supporting capacity planning and designing Kubernetes-based elastic applications."
}
@article{ALTHANOON2018262,
title = "Tuning parameter estimation in SCAD-support vector machine using firefly algorithm with application in gene selection and cancer classification",
journal = "Computers in Biology and Medicine",
volume = "103",
pages = "262 - 268",
year = "2018",
issn = "0010-4825",
doi = "https://doi.org/10.1016/j.compbiomed.2018.10.034",
url = "http://www.sciencedirect.com/science/article/pii/S0010482518303366",
author = "Niam Abdulmunim Al-Thanoon and Omar Saber Qasim and Zakariya Yahya Algamal",
keywords = "SCAD, Gene selection, Cancer classification, Penalized support vector machine, Firefly algorithm",
abstract = "In cancer classification, gene selection is one of the most important bioinformatics related topics. The selection of genes can be considered to be a variable selection problem, which aims to find a small subset of genes that has the most discriminative information for the classification target. The penalized support vector machine (PSVM) has proved its effectiveness at creating a strong classifier that combines the advantages of the support vector machine and penalization. PSVM with a smoothly clipped absolute deviation (SCAD) penalty is the most widely used method. However, the efficiency of PSVM with SCAD depends on choosing the appropriate tuning parameter involved in the SCAD penalty. In this paper, a firefly algorithm, which is a metaheuristic continuous algorithm, is proposed to determine the tuning parameter in PSVM with SCAD penalty. Our proposed algorithm can efficiently help to find the most relevant genes with high classification performance. The experimental results from four benchmark gene expression datasets show the superior performance of the proposed algorithm in terms of classification accuracy and the number of selected genes compared with competing methods."
}
@incollection{KELLER201813,
title = "Chapter 2 - Glossary of Mathematical Optimization Terminology",
editor = "André A. Keller",
booktitle = "Mathematical Optimization Terminology",
publisher = "Academic Press",
pages = "13 - 237",
year = "2018",
isbn = "978-0-12-805166-5",
doi = "https://doi.org/10.1016/B978-0-12-805166-5.00002-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780128051665000022",
author = "André A. Keller",
keywords = "Algorithm, Application, Block of information, Design, Entry, Item, Mathematical optimization, Mathematical Subject Classification (MSC 2010), Practical guide, Terminology",
abstract = "The academic literature includes many useful surveys to assess the origin and the circumstances of discovery and to put into perspective the evolution of a particular method. The user may also feel the need to refer to more focused, precise, and illustrated information that shows the value of an approach. The design of this presentation of terms is based on a chosen (nonexhaustive) set of items is user-oriented in view of its own applications. This central part of the book deals with the definition and presentation of entries on the mathematical optimization terminology in alphabetical order. The list aims to be complete in the sense of the contemporary dimensions of optimization. Each simple terminology is the subject of a comparable questioning to know the origin, the definition, mathematical formulation, and illustrations. An information block accompanying each entry includes useful data to facilitate a further study."
}
@article{KAMINSKI2015152,
title = "Adaptive neural speed controllers applied for a drive system with an elastic mechanical coupling – A comparative study",
journal = "Engineering Applications of Artificial Intelligence",
volume = "45",
pages = "152 - 167",
year = "2015",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2015.06.011",
url = "http://www.sciencedirect.com/science/article/pii/S0952197615001335",
author = "Marcin Kaminski and Teresa Orlowska-Kowalska",
keywords = "Neural networks, On-line adaptation algorithms, Speed control, Electrical drive, Two-mass system, Vibration damping",
abstract = "This paper presents an analysis and comparison of neural-adaptive controllers applied in a control structure of an electrical drive with an elastic mechanical coupling between the driving motor and a load machine, using only one state variable used in the feedback loop (a motor speed). However, the presented considerations can be assumed as a general neural speed control of the drive with a fast enough electromagnetic torque control loop of an electrical machine. This is justified by analogy with a design process independent of the parameters of a specific drive system and its electromagnetic torque control loop. Four types of neuro-controllers and training methods are analyzed: Adaptive Linear Neuron with Delta Rule, Multi-Layer Perceptrons Neural Network with the Backpropagation method, Feedforward Network with Adaptive Interaction adaptation and Radial Basis Function Neural Network with gradient algorithm, applied as speed controllers. Two main problematic issues related to neural controllers trained on-line are discussed: initial parameters selection for a neural network and determination of learning factors used in adaptation algorithms. Simulations are confirmed in experiment tests, using dSPACE1103 card. All the tested neurocontrollers are compared to a classical PI solution with one state variable used in the feedback loop of the analyzed drive system."
}
@article{MALAWSKI2017,
title = "Serverless execution of scientific workflows: Experiments with HyperFlow, AWS Lambda and Google Cloud Functions",
journal = "Future Generation Computer Systems",
year = "2017",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.10.029",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X1730047X",
author = "Maciej Malawski and Adam Gajek and Adam Zima and Bartosz Balis and Kamil Figiela",
keywords = "Scientific workflows, Cloud functions, Serverless architectures, FaaS",
abstract = "Scientific workflows consisting of a high number of interdependent tasks represent an important class of complex scientific applications. Recently, a new type of serverless infrastructures has emerged, represented by such services as Google Cloud Functions and AWS Lambda, also referred to as the Function-as-a-Service model. In this paper we take a look at such serverless infrastructures, which are designed mainly for processing background tasks of Web and Internet of Things applications, or event-driven stream processing. We evaluate their applicability to more compute- and data-intensive scientific workflows and discuss possible ways to repurpose serverless architectures for execution of scientific workflows. We have developed prototype workflow executor functions using AWS Lambda and Google Cloud Functions, coupled with the HyperFlow workflow engine. These functions can run workflow tasks in AWS and Google infrastructures, and feature such capabilities as data staging to/from S3 or Google Cloud Storage and execution of custom application binaries. We have successfully deployed and executed the Montage astronomy workflow, often used as a benchmark, and we report on initial results of its performance evaluation. Our findings indicate that the simple mode of operation makes this approach easy to use, although there are costs involved in preparing portable application binaries for execution in a remote environment. While our solution is an early prototype, we find the presented approach highly promising. We also discuss possible future steps related to execution of scientific workflows in serverless infrastructures. Finally, we perform a cost analysis and discuss implications with regard to resource management for scientific applications in general."
}
@incollection{BEAUMONT2015353,
title = "15 - Structural integrity and the implementation of engineering composite materials",
editor = "P.W.R. Beaumont and C. Soutis and A. Hodzic",
booktitle = "Structural Integrity and Durability of Advanced Composites",
publisher = "Woodhead Publishing",
pages = "353 - 397",
year = "2015",
series = "Woodhead Publishing Series in Composites Science and Engineering",
isbn = "978-0-08-100137-0",
doi = "https://doi.org/10.1016/B978-0-08-100137-0.00015-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780081001370000158",
author = "P.W.R. Beaumont",
keywords = "Damage mechanics, Failure mechanisms, Life prediction, Multiscale modelling, Physical modelling, Structural integrity, Virtual simulation",
abstract = "Predicting precisely where a crack will develop in a material under stress and exactly when catastrophic fracture of the component will occur is one the oldest unsolved mysteries in the design and building of large-scale engineering structures. Where human life depends upon engineering ingenuity, the burden of testing to prove a ‘fracture-safe design’ is immense. When human life depends upon structural integrity as an essential design requirement, it takes ten thousand material test coupons per composite laminate configuration to evaluate an airframe plus loading to ultimate failure tails, wing boxes and fuselages to achieve a commercial aircraft airworthiness certification. Fitness considerations for long-life implementation of engineering composites include understanding phenomena such as impact, fatigue, creep and stress corrosion cracking that affect reliability, durability of structure and life expectancy. Structural integrity (SI) analysis treats the design, the materials used, and figures out how best components and parts can be joined. Furthermore, SI takes into account service duty. However, there are conflicting aims in the complete design process of designing simultaneously for high efficiency and safety assurance throughout an economically viable lifetime with an acceptable level of risk."
}